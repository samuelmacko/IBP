%=========================================================================
% (c) Michal Bidlo, Bohuslav Křena, 2008

\chapter{Virtualization}
In first chapter I will explain what virtualiszation is and how it can be implemented.
\begin{itemize}
\item Virtualization basics,
\item Advantages,
\item Disadvantages,
\item Virtualization architectures.
\end{itemize}

\section{Virtualization basics}
In short, virtualization means emulation of hardware within a software platform. Although it may seem that virtuaization is the invention of last few years its concept was first brought up in 1960s. It was first implemented by IBM to split resources of their massive mainframe machines among multiple virtual machines that could work independently of each other and therefore use resources more efficiently.

To furher explain basics of virtualization I would like to start by brief explanation of architecture of standard computers. First, we need hardware layer which contains processing unit, storage and other hardware devices, on top of this layer is operating system which abstracts functioning of hardware layer and offers application layer medium to communicate with HW layer. Operating system runs as privilaged software which means that is generally able to perform any operation supported by hardware, its role is to create interface which simplifyes or ingores implemnentation of components on lower levels of a hierarchy to make creating and using components on application level easier. On top of operating system is application layer which consists of user programs whis are less privileged and can generally perform only operations that are permitted to them by operating system. [obrazok]

Virtualization allows creating multiple entities of os and application layers on single hw layer. This is done by inserting additional layer of system software between operating system and lower layers. This virtualization layer is called hypervisor or VMM (virtual machine monitor) and there are two main types of it:
\begin{itemize}
	\item Type I hypervisor (or bare-metal/native hypervispor): runs directly on host system's hardware with highes level of privilege and has full control over application layer running on top of it. Type I hypervisors have generally better performance than type II hypervisors because they don't have to communicate with hardware layer throught operating system thus can utilize full potencial it. Some of them need special priviledged virtual machine called Domain-0 from which it can be managed and controlled. [obrazok]

	\item Type II hypervisor (or hosted hypervisor): can be either on same level as host operating system or on a level above. This means that hypervisor doesn't require specific drivers for I/O operations and allows running of virtual environment within alredy existing environment. [obrazok popisujuci strukturu]
\end{itemized}

\section{Advantages}
As every other technology, virtualization have some advantages and disadvantages. Lets start with advantages:
\begin{enumerate}
\item Efficiency: Virtualization allows more efficient use of host machine for multiple virtual machines which can all run different services. Runnig multiple services on same server can be very dangerous multiple reasons and so it is considered a bad practice. Most obvious problem is with hardware overhead, if numerous very resource-demanding services run on single physical machine it can slow them down considerably or even crash them which makes business's services very unreliable. On the other hand, if we run only single service on whole physical host, that service can use for example only 20\% of server machine's resources (which is especially nowdays very common as hardware is becomming more and more powerful, average service utilizes only about 10\% to 15\% of all available resources). This way we waste remaining 80\% of resources which in the long unnecessarily raises expenses on managing physical hosts. Rather we can run various virtual servers on one physical hardware and on each of them run single service. Over past few years server technlogy has improved som much that wasting server's machine resources this way is very common and can by improved by virtualization. 

\item Cost reducing: By concentrating virtual machines on fever hosts we can reduce expenses associated with running large numbers of physical machines in various ways. We need less physical space for storing hosts, less cooling is needed, less energy is spent on powering all the hardware, managing fewer physical devices is also easier and cheaper. Companies with fewer than 1000 employees spend up to 40\% of their IT budget on hardware[], this can be greatly reduced by virtualization. Although this benefits more larger companies using plenty of server machines even smaller companies can benefit greatly from virtualization. Using less energy/space/etc means that virtualization is also firnedlier to environment.

\item Flexibility: Encreasing number of physical workstations or servers is financialy and time consuming process. We need new physical space, order new machines, set them up and so on. With virtual machines whole process is easier and faster. There are no more additional hardawe costs and administrators can easily setup and manage virtual machines using virtual machine management software. By using templates we can make creating new virtual machines even faster by automatization of setting up procedures. When hardware on which virtual machines are running becomes obsolete or it just needs to be out of service for maintenance resons we can easily migrate them to another physical hardware.

\item Testing: Virtual machines are completely isolated from each other which gives us possibility of testing environmnets with completely different operating systems and configurations. Even extreme situations are easy to set up and changed. Compared to physical machines, virtual machines can be added and removed very fast. QA teams often have multiple virtual machines with which they speed up testing and therefore development process.

\item Security: All virtual machines are isolated entities completely separated from every other software so when one of them gets attacked, gets virus or for any reason fails, only that one virtual machine fails and nothing other is affected. While problematic VM is diagnosed and repaired another VM can take it's place and continue running it's service which greatly reduces down-time and increases reliability of offered service.

\item Isolation: Virtual machines are hardware independent which means that their current state can be captured and reproduced on another physical host in process called migration. This reduces down-time even more becasue we can run all our services temporarily from another host while former host is being down due to maintenance. For example Red Hat Enterprise Virtualization supports live migration which is the ability to move running virtual machine between physical hosts with no interruption of service. The virtual machine remains powered on and user applications continue to run while the virtual machine is relocated to a new physical host. In the background, the virtual machine's RAM is copied from the source host to the the destination host. Storage and network connectivity are not altered. (citovane zo stranky red hatu)
\end{enumerate}

\section{Disadvantages}
Disadvantages: 
The disagvantages of virtualization are mostly those that are associated with any transition to a new technology and can be overcame by careful planing and professional implementation.
\begin{enumerate}
\item Overloading: this problem lies in wrong or uncomplete estimation of amount of hardware resources needed to handle desired virtual environment. Virtualizaion carries along additional bandwidth in form of hypervisor and other components which is not neglectable. Other extreme is not utilizing full potencial of physical host capabilities and wasting resources in long run by using more hosts that are actually needed. Basic rule of thumb is to use around 80\% of physical machines resources.

\item Bandwidth: the volume of data transfered through network might be noo much to handle for single network interface card (NIC), this can lead to slower network transfers. One of possible ways to solve this is to use host machine with multiple NICs.

\item Need for adjustments: in some cases, adapting a virtualization technology requires rewriting or patching some pieces of software to be compatible with virtual environment. 

\item Cost: To run multiple machines on single host mahine we need it to be sufficiently powerful. This means that additional investments into hardware may be needed. Another investments are into virtualization software and managing virtual machines.

\item Learning curve: conversion to and managing virtual environment will require IT staff with necessary training. The beginning stages can be painful due to lack of experience with new technology.

\item Vulnerability: altough virtualization brings certain security benefits it also bring a big risk in form of potencial damage cost by lower level layers corruptoion. In physical environment if operating system of one machine gets infected than only that one machine is affected but in virtualized environment if hardware, operating system or hypervisor of host gets damaged than all virtual machines running on it can potencially become unavailable. This problem can be reduced by regular backups and snapshots which allow easy transfer of virtual machines to a new host.

\item Licencing: majority of software vendors consider virtual machine exactly the same as physical machine so if certain piece of software is needed on multiple virtual machines (for exmaple operating system) than we have to pay for a licence for each one of them. We can try to solve this by using open-source software. This is becoming less of a problem nowadays because more and more software vendors are adjusting their view on virtualization.
\end{enumerate}


\section{Virtualization architectures}
Virtualization technology is spreading rapidly and today there are several architectures that implement this concept. Here are most used architectures and later we will discuss them in little more detail.
\begin{enumerate}
\item Full virtualization
\item Paravirtualization
\item Operating system virtualization
\item Other types of virtualization
\end{enumerate}

\begin{enumerate}
\item Full virtualization:  provides a total virtualization of hardware which means that every virtual entity runs as if was running on physical hardware completely unaware that its platform is virtualized. When a virtual machine wants to access hardware it access virtual hardware which access hypervisor which finally accesses physical hardware. Hypervisor thus acts as the only bridge between virtual machine and physical hardware. This is reason why full virtualization is in terms of performance behin non-virtualized machines.
\begin{enumerate}
\item Software assisted virtualization: [obrazok] historically first full virtualization solution introduced in 1969. This aproach has advantage in fact that if everything is simulated than any operting system or application can be run completly without modifications. On the other hand every operation made by operating system of virtual machine needs to be simulated and checked if it doesn't conflict with any other virtual machine or hypervisor which makes this process very resource-expensive.
\item Hardware assisted virtualization: [obrazok] introduced by IBM in 1972. This aproach reduces the problem of massive overhead in software assisted virtualization by extending functionality of hardware (mainly CPU) by new instructions allowing virtual machines to directly access physical hardware withou many expensive mediators. Normally x86 operating systems need to have a direct access to hardware resources, software-based virtualization solves this problem by virtualizing entire hardware layer but for price of wasting a big chunk of hardware resources. In hardware-base virtualization is this overhead noticibly reduced because processor no longer needs to be emulated and can directly interact with application layer. Another advantage is that it will work 'right of the box' meaning that we don't neeed to upgrade or change anything, all we need to do is to use processor supporting hardware-based virtualization technology.
\end{enumerate}

\item Paravirtualization: [k tomuto obrazok na hypercall] introduced in 1972 by IBM, this technique was implemented to increace performance of virtualized environmnet closer to non-virtualized. To use paravirtualization, kernel of the operating system needs to be modified, mainly it needs to have replaced any priviledged operation running only in ring 0 by so called 'hypercalls'. Hypercalls allow guest operating system to send system calls directly to he hypervisor without the need of hardware simulation. Virtual machine can therefore access some part of the hardware straight wihtout going throught virtualized hardware on top of hypervisor, which greatly increases performance of some operations. This only works for some parts of the hardware, for other parts, virtual machine still needs to access them via virtualized hardware. Paravirtualized virtual machine is 'aware' of the fact that it is being virtualized which gives it ability to use hypercalls. On the other hand, as mentioned above, in order to use this technique, operating system needs to be altered in a non-trivial way which typically limits its use to a Linux based operating systems because they allow such source code modifications.
Paravirtualization was popularized by Xen hypervisor, today, most virtualization solutions use it as a norm (for example Microsoft HYper-V, Red Hat Xen, VMware's family and others).

\item Operating system virtualization: [obrazok] (also known as shared kernel virtualization) introduces 'light-weight' virtualization. To understant this concept, first we need at least very basic understandig of what are kernel and root file system and are their roles. Kernel is central part of the operating system, simply put, it mediates communication between operating system and physical hardware. Root file system contains all the files, libraries and practically all utilities necessary for operating system to work properly. In shared kernel virtualization every virtual machine has its own root file system but uses host operating system's kernel which they share among each other. Kernel has the ability to dynamically switch the current root file system to a different one without the need to reboot the whole system (technique known as 'chroot'). In this case, virtual machines are reffered to as 'containers' due to the fact that they are not completely separated but share host machine's kernel. Shared kernel means very little overhead compared to other virtualization concepts and thus high performance. Despite its light-weight nature, this concept also supports advanced features such as isolating memory space, regulating memory, network, CPU and I/O usage, some implementations even allow live migration. Biggest advantage of container-virtualization is superior efficiency and very little overhead compared to other types of virtualization because it doesn;t have to emulate all the hardware. Interactions between software and hardware are handled by operating systems kernel inside container. Major disadvantage of this technique is that container's operating system must be compatible with kernel on which it runs (container operating system must be designed for type and version of kernel that is being shared). Further, container environments cannot execute some top-level actions, mount/dismount file systems and so on whereas fully virtualized solutio gives us fully independent environment in which isn't user restricted in any way.
Well known solutions are Linux VServer, Jail for FreeBSD, Zone for Solaris, Virtuozzo for Windows, Rosetta for Mac OS and others.

\item Other types of virtualization:
\begin{enumerate}
\item Network virtualization: main idea is to create multiple virtual sub-networks (channels) that run on single physical network and are idependent from one another. Each one of virtual networks can have different bandwidth related, security or other restrictions and we can regulate trafic on each channel independently.  Monitoring individual networks with their own purposes and settings is also easier and faster, it increases reliability and durability of network too as if one of virtual networks is for whatever reason overloaded or down other networks are not affected. Most modern hypervisors implement virtual networking in some form. Network virtualization can be further divided into two sub-categories:
\begin{enumerate}

\item Internal: can be used for communication between software and virtual machines or to mimic network to external devices. Internal network uses virtual network devices that act as physical devices and enables single system to appear as a network.

\item External: used in Virtual local area networks (VLAN) and Virtual private networks (VPN).
\end{enumerate}

\item Application virtualization: this technique separates the application layer from the underlying operating system layer which means that application runs in 'encapsulated' state independently from operating system. Application is put into a capsule into which is then put copies of al shared resources that application would need to run as well as all DLLs (dynamicaly linked libraries), driver, registry entries and so on. In practical terms it means that application created for certain operating system can run on a different one, for example native Windows applications can be run under Linux distribution or vice-versa, we can isolate suspicious or malicious software and inspect it without the danger of infectiong whole system, run simultaneously applications that would otherwise conflict each other, easily deploy applications and so on. Some well known examples are Wine which is used to run Microsoft Windows applications on Linux, ThinApp from VMware, Xenocode from Code System Corporations and others.

\item Desktop virtualization: similarly as application virtualization it separates desktop environment from underlying physical computer. Desktop virtualization functions on a client-server model. Clinet desktop environments are running on virtual machines stored on servers and client can access them via client device which can be standard PC or thin client. This technique is growing on popularity mainly because of cloud computing. It allows us to access desktop from any device or location (in practical terms it means that we can work in same environment from anywhere without the need to bring 'work computer'). By isong desktop virtalization we can use cheaper client desktop devices because far less processing power is required. Of course, businesses need to first invest into server hardware so it is capable of storing and streaming desired quantities of desktop environments but will save money in a long run by cheaper user devices. Desktop environments are stored on central server so they can be also centrally managed and controlled which increases security of whole system. Disadvantage is that streaming desktop environments to plenty of end users is very demanding on network infrastracture. Desktop virtualization is mostly used by companies with a lot of off-shore employees.

\item Storage virtualization: multiple separated hardware storage devices (that can be on different physical locations) abstracted into single pool of virtualized storage space that act as single sotrage device localy connected to the computer. Storage virtualization is used to ignore differences between individual storage devices and simplify using them. It is ofthen used for back-ups and archives and can be implemented with software or hybrid software-hardware solutions. Common examples are:
\begin{enumerate}
\item NAS: (Network-attached storage) is server dedicated to managing storage space. NAS devices have to be part of LAN and they can be added or removed dynamically meaning that after adding/removing device whole system doesn't need to be restarted but it continues functioning as if nothing have happened.
\item SAN: (Sotrage area network) is basically a sub-network containing only storage devices. Storage space managet by SAN can be accessed by any server in LAN or WAN. When new storage devices is added it is immediately available to any server in network. In practice SAN enables anyone within network have access to network's whole storage space.
\end{enumerate}
\end{enumerate}
\end{enumerate}


\chapter{Virtualization software}
In this chapter we will go through well known virtualization implementations divided to virtualization architectures.
\begin{enumerate}
\item Xen Project
\item KVM
\item VirtualBox
\item UML
\item Docker Container
\item Wine
\end{enumerate}

\section{Xen Project}
Is well known type I hypervisor which means it runs directly on the host hardware. Xen Project is widely used as base for a number of open-source and commercial applications providing server virtualization, desktop virtualization, infrastracture as a service (IaaS), security aplications, embedded and hardware appliances and so on. Worlds bigest clouds today also run on Xen Project hypervisor base. All operating systems based on recent Linux kernel are capable of running Xen project and have packages containing hypervisor and basic tools.

Xen is managed by a special priviledged virtula machine called Domain-0 or Dom0, priviledged means that it has device drivers and direct access to physical hardware. Domain-0 is a specially modified Linux kernel which is started by Xen hypervisor during initial stage of system start-up(OPISANE). Its role is to manage and control every other unpriviledged virtual machines (also called Domain-Us or DomU) that are running on the hypervisor. Domain-0 exposes control interface to the user and Xen project hypervisor cannot run without it. Through user interface in form of toolstack (or control stack) user can create, destroy or configure virtual machines, toolstack can by driven by command line console, graphical interface or cloud orchestration stack (for example OpenStack or CloudStack). [OBRAZOK]

Originally Xen only supported Paravirtualization (see link Paravirtualization). Support for Domain-U running in paravirtualized state is now included within upstream Linux kernel but support fo Domain-0 is not which means that it is easier to use Linux machine as a guest than as a host. Nowadays Xen supportste new virtualization processor extension added to the x86 architecture(aj tu), this is known as Xen as Hardware Virtual Machine (HVM). HVM allows unmodified guest operating system to be virtualized on Xen hypervisor(aj tu) but it requires a special processors that support hardware virtualizaton extensions (Intel VT, AMD-V). These extencions allow for many of the priviledged kernel instructions to be handled directly by hardware using 'trap-and-emulate' techique, these were previously in paravirtualization converted to hypercalls.

Trap-and-emulate: Operating systems running on top of the hypervisor are run as user-level processes. They are not running at the same level of privilege as a Linux operating system that is running on bare metal. But if the operating system code is unchanged, it doesn’t know that it does not have the privilege for doing certain things that it would do normally on bare metal hardware. In other words, when the operating system executes some privileged instructions, meaning they have to be in a privileged mode or kernel mode to run on bare metal in order to execute those instructions, those instructions will create a trap that goes into the hypervisor and the hypervisor will then emulate the intended functionality of the operating system. This is what is called the trap and emulate strategy. That is in some architectures, some privilege instructions may fail silently which means that you would think that the instruction actually succeeded, but it did not, and you may never know about it.

Here are key features of Xen project hypervisor:
\begin{enumerate}
\item Minimal footprint: around 1 MB. Xen uses microkernel design which minimalizes memory footprint and interface to the guest and is also more robust and secure than other types of hypervizors.
\item Driver isolation: hypervisor allows for the main device driver to run inside of a virtual machine. This is useful because if driver crashes it does not affect any other part of a system and virtual machine in which it runs can be rebooted and the driver restarted.
\item Many operating systems can be used: although most installaions use Linux as the domain-0 many other operating systems can by used such as NetBSD, OpenSolaris and others.
\end{enumerate}


\section{KVM}
[obrazok] KVM - Kernel-based Virtual Machine lesser known virtualization solution then Xen Project. It has host and guest support in an upstream Linux kernel released in early 2007. KVM is kernel module which when loaded turns host kernel into type I hypervisor. To run it requires Intel VT or AMD-V extensions and enabled on a host system. By converting host machine kernel into hypervisor KVM can take advantage of already implemented components instead of implementing them from the scratch, for example it uses memory manager, scheduler, I/O stack, device drivers, security manager, network manager and others. In comparason to Xen architecture which requires maintenance of both Xen hypervisor and Domain-0, KVM is loadable kernel module and is easier to patch and upgrade. From host's perspective, every virtual machine is standard linux process and is treated as such.

Features:
\begin{enumerate}
\item Security: to improve security of virtual machines even further, KVM uses these approaches:
\begin{enumerate}
\item Security-enhanced Linux (SELinux) which establishes security boundaries around virtual machines.
\item Secure virtualization (sVirt) which boosts SELinux's capabilities and allow Mandatory Access Control (MAC) security to be applied.
\end{enumerate}
\item Live migration: KVM supports live migration(see live migration) of virtual machines.
\item Scheduling and resource control: every virtual machine is seen as a standard process which means that Linux scheduler allow full control over resources allocated by it and guarantees quality of service. KVM offers completely fair scheduler, control groups, network name spaces and real-time extensions.
\item Storage: KVM supports shared file system which means that virtual machines can be shared by multiple hosts. Disk images support thin provisioning. Thin provisioning means that memory is allocated for virtual machine up to provisioned amount only when it needs it (Xen Project doesn't support thin provisioning, when vitual machine is provisioned for example 2 GB of RAM, after it starts, 2 GM of RAM are immediately allocated and can't be used elsewhere). This can lead to 'memory overcommit', state where more memory is assigned to virtual machines than is available on the system. KVM deals with memory overcommit in various ways:
\begin{enumerate}
\item Host can choose memory pages and write them to the disk. This leads to redcing performance as when virtual machine wants to access memory, host needs to read it from the disk which is significantly slower than RAM.
\item With VirtIO drivers, hot can request virtual machines to shrink their cache memory in order to free as much space as needed. This is called 'ballooning' and requires cooperation among host and guests.
\item KSM (Kernel Samepage Merging) is a process of merging identical memory pages from multiple virtual machines into a snigle read-only memory chunk while removing all duplicates of it. If any guest needs to write into one of merged pages, host creates writable copy which guest can modify.
\end{enumerate}
\item Lower latency: kernel divides processes with long computing times into smaller pieces which are scheduled and processes acordingly.
\end{enumerate}


\section{VirtualBox}
VirtualBox is a type II hypervisor currently being developed by Oracle Corporation. Oracle VM VirtualBox runs on Microsoft Windows, Mac OS X, Linux and Oracle Solaris systems and supports wide range of guest operating systems. With thousands of downloads each day it is the most popular cross-platform open-source virtualization solution.

Here are some of VirtualBox's main features:
\begin{enumerate}
\item Portability: VirtualBox has to run on an host operating system but its functionallity is to a very large degree identical on all of them, same files and image formats are used. This allow us to create a virtual machine on one host and run it on another host with different operating system. Virtual machines can be imported and exported using an Open Virtualization Format (OVP) with which we can import virtual machines created with different virtualization software.
\item No hardware virtualization needed: VirtualBox doesn't require a processor support like Intel VT or AMD-V so it can be run even on older hardware not possessing those features.
\item Guest additions: guest additions are software packages that can be installed inside of virtual machines to improve their performance or improve their integration with host system. They consist of device drivers and system applications, for example on of guest additions is 'Shared folders addition' which provides an easy way to exchange files between host and guest. We can create a folder on host system and share it to the guest.
\item Hardware support:
\begin{enumerate}
\item Guest multiprocessing: VirtualBox can present up to 32 virtual CPUs to every virtual machine regardless of how many CPUs are present in host system.
\item USB device support: virtaul USB controller allows to connect USB device to virtual machine without a need to install device-specific drivers to the host machine.
\item ACPI support: Advanced Configuration and Power Interface is an open standard that operating systems can use to configure hardware components and to perform power management and status monitoring.
\item Built-in iSCSI support: this allows us to connect from virtual machine directly to the iSCSI storage server without going through host system which
highly reduces overhead.
\item PXE support: Preboot eXecution Environment (PXE) in short is a way to boot operating system from a server on a virtual machine. Advantages are obvious, we don't need to have a operating system on a hard drive connected to the virtual machine, we just need to connect to server and boot it from there.
\end{enumerate}
\item Snapshots: we can create snapshots of the current state of a virtual machine and store it. When needed we can reverse current state of VM and load configuration from any snapchot. This way we can periodicly save backups for quick recovery in case of emergency.
\item Grouping: multiple virtual machines can be collected into a group. We can than perform same operations over the group as we can over individual virtual machines (for example start, pause, shutdown, close, ...). By using groups we can manage multiple virtual machines with same configuration, purpose, etc at the same time as well as we can still manage individual VMs that are part of a group. One virtual machine can be inside multiple groups and groups can be nested into hierarchy.
\item Remote machine display: VRDE - VirtualBox Remote Desktop Extension allows for a high-performance remote access to any running virtual machine.
\end{enumerate}


\section{UML}
[obrazok] User Mode Linux (UML) allows us to run Linux kernels as user mode processes under a host Linux kernel thus allowing us to run multiple independent virtual machines. Main difference between UML and other virtualization technologies is that UML is more of a virtual OS than virtual machine. Other solutiuons like VMWare are real virtual machines in that they emulate physical hardware and any operating system that runs on physical platform can also run on emulated one. Advantage of this solution is that guest OS is host OS-independent, meaning that any OS able to run on hardware is able to run on top of VMWare. On the other hand, UML is basicaly just Linux kernel modified to run in user space, UML guest can run only on Linux platform which is serious limitation but being more of virtual OS has other advantages. Solutions such as Xen, BSD jail or Solaris zones are integrated into host operating system but UML runs as a process. This has some performance costs but gives UML host OS version independence. UML has many real-world uses but it's most popular use-case is kernel development and debugging as it was its original purpose, for that can be used normal process-level tools like gdb, gporf (profiling) or gcov (coverage testing). Another popular uses are driver development, safe kernel testing and education due its simpler nature than other solutions.


\section{Docker Container}
Docker container is a operating system level technology established  and promoted by Docker Inc. Docker container is operated by command-line tool called the Docker client which can run on the container host or through a remote interface connected to the container host. The main task of a Docker client is to pull images of containers from registry. Registry can be public or private and it is a repository of sources for 'ready to run' virtual workloads. Main public registry is Docker Hub which is operated by Docker Inc. but nowadays there are planty of others. We can pull a container image using Docker daemon and from that image we can build working model for that container. A container is launched by running an image. An image is an executable package that includes everything needed to run an application–the code, a runtime, libraries, environment variables, and configuration files. Images that are mostly the same, except for the last few steps, can reduce disk usage by sharing parent layers. A container is a runtime instance of an image–what the image becomes in memory when executed (that is, an image with state, or a user process). Image can also include directives for daemon to preload the container with other components prior to running or directives for the loca command line after the local container image is build. The model of images and registries created standardized ways to build, load and manage containerized applications. Docker has been very successful in building a large open-source community which has contributed to the rising number of images in public and private repositories which attracts even more developers and enlarges open-source community. Docker image is defined by text-based Dockerfile which specifies a vase operating system image to start from, commands to prepare/build the image and commands to call whne image is 'run'. (Docker runs multiple containerized workloads on the same OS. By using containers, only the programs and their immediate dependencies are hosted by containers, with critical resources provided by the underlying operating system.  This means that containerized systems can load applications faster and consume less resources.). Docker is available on many different operatin systems including most modern Linux distributions, Mac OSX and Windows.

OCI: The Open Container Initiative (OCI) is a lightweight, open governance structure (project), formed under the auspices of the Linux Foundation, for the express purpose of creating open industry standards around container formats and runtime. The OCI was launched on June 22nd 2015 by Docker, CoreOS and other leaders in the container industry [citovane]. The OCI currently contains two specifications: the Runtime Specification (runtime-spec) and the Image Specification (image-spec). The Runtime Specification outlines how to run a “filesystem bundle” that is unpacked on disk. [tiez]

Docker Engine is a client-server application with these major components:
\begin{enumerate}
\item A server which is a type of long-running program called a daemon process
\item A REST API which specifies interfaces that programs can use to talk to the daemon
\item A command line interface (CLI) client
\end{enumerate}
Docker uses a client-server architecture. The Docker client talks to the Docker daemon, which does the heavy lifting of building, running, and distributing Docker containers. The Docker client and daemon can run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and daemon communicate using a REST API.
A Docker registry stores Docker images. Docker Hub and Docker Cloud are public registries and Docker is configured to look for images on Docker Hub by default. We can run our own private register. We can also buy or sell Docker images or distribute them for free in Docker store.

Docker uses a technology called namespaces. When we run a container, Docker creates a set of namespaces for it. These namespaces provide a layer of isolation. Each aspect of a container runs in a separate namespace and its access is limited to that namespace.
On Linux, Docker Engine uses these namespaces:
\begin{enumerate}
\item pid: process isolation
\item net: managing network interfaces
\item ipc: managing access to IPC resources
\item mnt: managing filesystem mount points
\item uts: isolationg kernel and version identifiers
\end{enumerate}


\section{Wine}
Wine - Wine Is Not an Emulator acronym means that Wine is not a virtual machine, it doeas not emulate physical hardware and we are not supposed to install Windows or any Windows driver on top of it. Different software programs are designed for different operating systems and are generaly not compatible with other operating systems, for example Windows programs can't run on Linux system because they use instructions that Linux system doesn't understand thus cannot interpret them, this is the main motivation for Wine. Wine is an implementation of Windows API and can be used as a library to port Windows applications to Unix, basicaly acting as a bridge between the two. It is a compatibility layer, everytime a Windows program tries to perform an action that Linux doesn't recognize, Wine will transalte it into one that it does. Wine can also recompile Windows program source code into format understandable for Linux. Even in recompiled form, Wine is still needed to run the program but there are many performance and other advantages to this process. Wine is an open source project.

Features:
Wine is constantly growing in the features it supports, here are some of them:
\begin{enumerate}
\item Support for running, Win64, Win32, Win16 and Dos programs.
\item Optional use of external vendor DLLs.
\item MacOS and Android graphics support.
\item DirectX for games.
\item Support for alternative input devices such as graphics tablets
\item Winsock TCP/IP networking support.
\item Advances Unicode and foreign language support.
\item Fill featured Wine debugger and configuratable trace logging messages for easier troubleshooting.
\end{enumerate}

Executables:
Wines main task is to run Windows executebles, here are supported types:
\begin{enumerate}
\item DOS executable: very old programs for MS-DOS.
\item Windows NE executable: (NE - New Executable) They were the native processes run by Windows 2.x and 3.x.
\item Windows PE executable: (PE - Portable Executable) Introduced by Windows 95 and became the standard format for all later Windows versions. Portable Executable means that format of the esxecutable is independent of the CPU, even if the code IS dependent of the CPU.
\item Winelib executable: aplications written by using the Windows API but compiled as a Unix executable.
\end{enumerate}

Wine architecture is close to the Windows NT architecture but several subsystems are not implemented yet.
[obrazky]


\chapter{Products for virtualization}

Even though virtualization technology was introduced more than 20 years ago it experienced a big boom only in past few years. There are now many companies developing some sort of virtualization technology and offering different productsto. This is great for customers which can choose from wide variety of virtualization tools depending on type/price/scale and so on. Every year more and more companies decide to virtualize their servers for reasons we look through in chapter 1(?). In this chapter we will look at biggest or fastest growing virtualization companies today and present som of their products

\begin{enumerate}
\item VMware
\item Citrix
\item Oracle
\end{enumerate}

\section{VMware}

Products:
\begin{enumerate}
\item VMware Workstation: Is basically industry standard for desktop virtualization - it is a hosted hypervisor. Workstation runs on Windows or Linux and can also run virtual machines with Windows or Linux operating system. Initially launched in 1999 is one of the longest running modern day virtualization applications. VMware Workstation Pro can save the state of a virtual machine as a snapshot which can later be restored, effectively returning the virtual machine to the saved state. It can also group multiple virtual machines into an inventory folder with which we can control (power on/off) all the virtual machines inside it at once.
Key features:
\begin{enumerate}
\item High-performance 3d graphics: Workstation supports DirectX 10 and OpenGL 3.3 to run the most demanding 3D applications with near-native performance in Windovs virtual machines.
\item Massive virtual machines: with Workstation we can create virtual machines up to 16 CPUs, 8 TB virtual disks and 64 GB of memory to run high-performance demanding desktop and server applications in virtualized environments. To improve graphics performance we can allocate  up to 2 GB of available host video memory.
\item High resolution display support: Workstation supports high-resolution display for desktops and also multiple displays.
\item Restricted access to virtual machines: virtual machine can be encrypted and protected by password.
\item Cross compatibility: we can create virtual machines that can run across the VMware product portfolio or even import VMs from another vendors.
\end{enumerate}
\item VMware Fusion Pro: VMware Workstation Pro for Mac operating systems.
\item Workstation Player: is 'lighter' verion of Workstaion. It runs on same core as Workstation Pro and vSphere but delivers lesser features. On the other hand it is free of charge for personal non-cmmercial use. Wokrstation player can still create and run virtual machine, but only one at a time instead of multiple virtual machines simultaneously. It aslo cannor create or manage encrypted VMs and so on. Workstation Pros is great for 'feeling up' virtualization before investing into full blown solutions or for simple personal use.
\item VMware vSphere: serves as a complete platform for implementing and managing virtual machine infrastructure on large scale. vSphere consists of two core components: ESXi and vCenter Server.
\begin{enumerate}
\item ESXi is a bare-metal (type I) hypervisor. It has small footprint (150 MB) which minimizes security threats to the hypervisor. It can support up to 128 virtual CPUs, 6 TB of RAM and 120 devices and offersbuilt-in UI based on HTML5 standards, vSphere comman line interface and REST-based APIs. Thin architecture enables it to install in 10 minutes and boot 2 to 3 minutes.
\item vCenter Server: provides a centralized platform for managing VMware vSphere enironment, allowing automation and delivery of virtual infrastructure. From single vCenter instance can be managed up to 1000 hosts and 10000 virtual machines, these numbers can be scaled by using Linked Mode for managing up to 30000 virtual machines across 10 vCenter Server instances and vSphere HA for even more hosts and VMS. Linked Mode replicates roles, permissions and licences across infrastructure so we can log in and view inventories of all vCenter Servers. We can use 3rd-party plug-ins created by VMware partners. With open Web CLient Plug-in SDK vCenter Server has largest partner ecosystem in industry which means that we can implement back-up, data protection, server, network and security management directly from vCenter. Web Client Plug-in Certification Program ensures better end-user experience. Certified Plug-ins deliver optimal performance, better security model and so on. We can also back up vCenter Appliances to a file via industry standar protocols. In case of need we can point a fresh appliance to a backup location and files will be downloaded to the new vCenter Server Appliance.
\end{enumerate}
\item VMware ThinApp: is VMware's solution for application virtualization. ThinApp uses a build process to package application files and registry settings into a single application container that can be executed on a variety of operating systems without installation. Applications can be executed from a user’s desktop, a network path, or removable media. Applications run entirely in user mode under the security context of the currently logged in user. To virtualize an application ThinApp uses a Capture and Build process which consists of two components:
\begin{enumerate}
\item Setup Capture: The Setup Capture wizard guides the process of capturing the application and applying administrator-supplied configurations specific to the package. Setup Capture takes a prescan snapshot, allows the administrator to install and configure the application, and takes a postscan snapshot. The difference between the prescan and postscan snapshots, which represents the application, is placed in the project directory.
\item The process by which the project directories and configuration settings are compressed and embedded into the package.
\end{enumerate}
\end{enumerate}

\section{Citrix}
Citrix Systems, Inc. is an American multinational software company that provides server, application and desktop virtualization, networking, software as a service (SaaS), and cloud computing technologies. The company began by developing remote access products for Microsoft operating systems. It licensed source code from Microsoft and has been in partnership with the company throughout its history. Citrix came to prominence in the 1990s as a leader in thin client technology, purpose built for accessing remote servers. The company had its first initial public offering in 1995 and, with few competitors, experienced large revenue increases between 1995 and 1999. Between 2005 and 2012, Citrix acquired more than a dozen other companies, allowing it to expand into server and desktop virtualization, as well as others.

\subsection{XenServer}
XenServer is the complete server virtualization platform from Citrix. The XenServer package contains everything needed to create and manage a deployment of virtual x86 computers running on Xen, the open-source paravirtualizing hypervisor with near-native performance. XenServer is optimized for both Windows and Linux virtual servers. XenServer runs directly on server hardware without requiring an underlying operating system (type I hypervisor). There are two methods by which to administer XenServer: XenCenter and the XenServer Command-Line Interface (CLI). XenCenter is a graphical, Windows-based user interface. XenCenter allows you to manage XenServer hosts, pools and shared storage, and to deploy, manage and monitor VMs from your Windows desktop machine. Key features include creating virtual machine templates from snapshots, XenMotion which allows us to live migrate VMs between hosts. XenServer 7 provides support for high-performance enhanced 3D graphics, with the widest variety of GPU pass-through and virtualized GPU vendor options. Only XenServer includes support for Intel’s Virtual Graphics Technology (GVT-g), a CPU embedded GPU with no extra hardware required to facilitate enhanced graphics workloads. Starting with Citrix XenServer 7, the Enterprise version includes Direct Inspect APIs which allow third-party vendors to secure the OS.

\subsection{XenDesktop}
XenDesktop is a desktop virtualization software platform developed and sold by Citrix Systems, that allows multiple users to access and operate Microsoft Windows desktops. These desktops are installed at a centralized server separate from the devices from which they are accessed. Citrix XenDesktop contains a powerful profile management tool that manages profiles independently from the OS and delivers required profile data on-demand. XenDesktop also includes Citrix Receiver, a universal client built for virtually any device including Windows, Mac, Linux, iOS, Android, Chrome OS, Blackberry and for environments that desire a clientless HTML5 web Receiver. XenDesktop includes a Windows app store delivered by Citrix StoreFront to provide a single aggregation point for all IT user services. Users may subscribe to applications, desktops, or data services from any device and have access to those same services, even when already in use from any other device.

\subsection{XenApp}
Citrix XenApp is application virtualisation software that allows Windows applications access via individual devices from a shared server or a Cloud system. We can have applications installed on a XenApp server in a data centre and launch them on any device (laptop/tablet/etc.). Application can be accessed from range of operating systems but streamed applications have to run on Windows.


\section{Oracle}
Something about Oracle.

\subsection{Oracle VM}
Oracle VM is a platform that provides a fully equipped environment with all the latest benefits of virtualization technology, it nables us to deploy operating systems and application software within a supported virtualization environment.
Architecture of Oracle VM is composed of these parts:
\begin{enumerate}
\item Client Application: Oracle VM provides various user interfaces, we can use either CLI (command line interface) through SSH client, GUI accesible over web-browser or external applications such as Oracle Enterprise Manager, custom built applications or scripts using the Web Services API. All communication with Oracle VM Manager is secured using either a key or certificate based technology.
\item Oracle VM Manager: used to manage Oracle VM Server, virtual machines and resources and is composed of mutiple subcomponents functioning as one unit. It usually runs on stand alone computer but can also run as a virtual machine however this method is restricted and not fully supported. Core application is Oracle WebLogic application running on Oracle Linux. Oracle VM Manager communicates with each Oracle VM Server via the Oracle VM Agent, using XML-RPC (Remote Procedure Call using XML) over HTTPS.  The Oracle VM Agent on each Oracle VM Server is equally able to send notifications, statistics and event information back. Even though Oracle VM Manager is critical component for configuration in Oracle VM infrastructure, the virtualized environment can run correctly even if Oracle VM Manager experiences downtime, still maintaining high availability and able to live migrate virtual machines on x86 platform.
\item Oracle VM Manager Database:  Used by the Oracle VM Manager core application to store and track configuration, status changes and events. . Oracle VM Manager uses a MySQL Enterprise database that runs on the same host as Oracle VM Manager. The database is used exclusively by Oracle VM Manager and cannot be used by any ither application. It is automatically and periodically backed-up and can be also backed-up manually.
\item Oracle VM Server: a virtualization environment providing a lightweight and secure server platform for running virtual machines. At least one Oracle VM Server is required, but to take advantage of clustering several are needed. Oracle VM Server is installed on a bare metal computer, and contains the 
Oracle VM Agent to manage communication with Oracle VM Manager. On x86-based systems, Oracle VM Server is based on an updated version of Xen hypervisor technology. In case of SPARC, Oracle VM Server takes advantage of the hypervisor that is already included within SPARC firmware. Groups of Oracle VM Servers are usually clustered together to create server pools. This allows Oracle VM Manager to handle load balancing. Virtual machines running within a pool can be easily moved between servers in that pool. In Oracle VM infrastructure server pools are required even if they consist of only one server.
\item External Shared Storage:  Provides storage for a variety of purposes and is required to enable high-availability options afforded through clustering.
\end{enumerate}


%=========================================================================
